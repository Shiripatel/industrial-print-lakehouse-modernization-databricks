{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05dc7ff6",
   "metadata": {},
   "source": [
    "# 01 â€“ Bronze Ingestion\n",
    "\n",
    "This notebook simulates ingestion of raw JSON data from the industrial print workflow system into **Bronze Delta tables**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0179ba4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import current_timestamp\n",
    "\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", \"1\")\n",
    "\n",
    "orders_path = \"/mnt/bronze/orders\"\n",
    "providers_path = \"/mnt/bronze/providers\"\n",
    "events_path = \"/mnt/bronze/events\"\n",
    "\n",
    "raw_orders = spark.read.json(\"dbfs:/FileStore/industrial_print/samples/sample_orders.json\")\n",
    "raw_providers = spark.read.json(\"dbfs:/FileStore/industrial_print/samples/sample_providers.json\")\n",
    "raw_events = spark.read.json(\"dbfs:/FileStore/industrial_print/samples/sample_events.json\")\n",
    "\n",
    "raw_orders = raw_orders.withColumn(\"ingest_ts\", current_timestamp())\n",
    "raw_providers = raw_providers.withColumn(\"ingest_ts\", current_timestamp())\n",
    "raw_events = raw_events.withColumn(\"ingest_ts\", current_timestamp())\n",
    "\n",
    "raw_orders.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"industrial_print.bronze.orders\")\n",
    "raw_providers.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"industrial_print.bronze.providers\")\n",
    "raw_events.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"industrial_print.bronze.events\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}